<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Camera Assistant</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #74b9ff 0%, #0984e3 100%);
            min-height: 100vh;
            color: #2d3436;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }

        .container {
            max-width: 800px;
            width: 100%;
            text-align: center;
        }

        .header {
            margin-bottom: 30px;
            background: rgba(255, 255, 255, 0.95);
            padding: 20px;
            border-radius: 20px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
        }

        .header h1 {
            font-size: 2.2rem;
            color: #0984e3;
            font-weight: 700;
            margin-bottom: 10px;
        }

        .camera-section {
            background: rgba(255, 255, 255, 0.95);
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
            margin-bottom: 20px;
        }

        #video {
            width: 100%;
            max-width: 640px;
            height: 400px;
            object-fit: cover;
            border-radius: 15px;
            border: 3px solid #0984e3;
            margin-bottom: 20px;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
        }

        .controls {
            display: flex;
            gap: 20px;
            justify-content: center;
            margin-bottom: 20px;
            flex-wrap: wrap;
        }

        .btn {
            padding: 15px 30px;
            border: none;
            border-radius: 50px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            gap: 8px;
            min-width: 160px;
            justify-content: center;
        }

        .btn-primary {
            background: linear-gradient(45deg, #0984e3, #74b9ff);
            color: white;
        }

        .btn-primary:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 8px 25px rgba(9, 132, 227, 0.4);
        }

        .btn-voice {
            background: linear-gradient(45deg, #00b894, #00cec9);
            color: white;
        }

        .btn-voice:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 8px 25px rgba(0, 184, 148, 0.4);
        }

        .btn-voice.listening {
            background: linear-gradient(45deg, #d63031, #e84393);
            animation: pulse 1.5s infinite;
        }

        .btn:disabled {
            opacity: 0.6;
            cursor: not-allowed;
            transform: none;
        }

        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }

        .voice-status {
            background: rgba(255, 255, 255, 0.9);
            border-radius: 15px;
            padding: 15px;
            margin-top: 15px;
            font-size: 16px;
            color: #2d3436;
            min-height: 50px;
            display: flex;
            align-items: center;
            justify-content: center;
            border-left: 5px solid #0984e3;
        }

        .voice-status.listening {
            background: #fff3cd;
            border-left-color: #ffc107;
            color: #856404;
        }

        .voice-status.processing {
            background: #d4edda;
            border-left-color: #28a745;
            color: #155724;
        }

        .voice-status.speaking {
            background: #cce5ff;
            border-left-color: #007bff;
            color: #004085;
        }

        canvas {
            display: none;
        }

        @media (max-width: 768px) {
            .header h1 {
                font-size: 1.8rem;
            }
            
            #video {
                height: 300px;
            }
            
            .controls {
                flex-direction: column;
                align-items: center;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>Voice Camera Assistant</h1>
        </div>

        <div class="camera-section">
            <video id="video" autoplay playsinline></video>
            <canvas id="canvas"></canvas>
            
            <div class="controls">
                <button id="captureBtn" class="btn btn-primary" onclick="captureImage()">
                    📷 Capture
                </button>
                <button id="voiceBtn" class="btn btn-voice" onclick="toggleVoiceInput()">
                    🎤 Ask Me
                </button>
            </div>
            
            <div id="voiceStatus" class="voice-status">
                Camera will start automatically. Capture an image or just ask me anything!
            </div>
        </div>
    </div>

    <script>
        // API configuration
        const GEMINI_API_KEY = "AIzaSyAmei6RqPdLYC6tyHWllajLSNhqjUplkCw";
        const OPENROUTER_API_KEY = "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";

        // Global variables
        let video, canvas, ctx;
        let currentImageDescription = '';
        let chatHistory = [];
        let recognition;
        let isListening = false;
        let currentUtterance = null;
        let cameraStarted = false;
        let isSpeaking = false;

        // Initialize the application
        document.addEventListener('DOMContentLoaded', function() {
            video = document.getElementById('video');
            canvas = document.getElementById('canvas');
            ctx = canvas.getContext('2d');

            // Auto-start camera
            startCamera();
            
            // Initialize speech recognition
            initializeSpeechRecognition();
        });

        // Start camera automatically
        async function startCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { width: 640, height: 480 } 
                });
                video.srcObject = stream;
                cameraStarted = true;
                
                updateStatus('Camera ready! You can capture images or just talk to me about anything!', '');
            } catch (error) {
                console.error('Error accessing camera:', error);
                updateStatus('Error accessing camera. Please check permissions!', '');
            }
        }

        // Initialize Speech Recognition
        function initializeSpeechRecognition() {
            if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                recognition = new SpeechRecognition();
                recognition.continuous = false;
                recognition.interimResults = false;
                recognition.lang = 'en-US';

                recognition.onstart = function() {
                    isListening = true;
                    document.getElementById('voiceBtn').classList.add('listening');
                    document.getElementById('voiceBtn').innerHTML = '🎤 Listening...';
                    updateStatus('Listening... Ask me anything!', 'listening');
                };

                recognition.onresult = function(event) {
                    const transcript = event.results[0][0].transcript;
                    updateStatus(`You said: "${transcript}"`, 'processing');
                    
                    // Process the question
                    setTimeout(() => {
                        askQuestion(transcript);
                    }, 1000);
                };

                recognition.onerror = function(event) {
                    updateStatus('Sorry, I couldn\'t hear you clearly. Try speaking again!', '');
                };

                recognition.onend = function() {
                    isListening = false;
                    document.getElementById('voiceBtn').classList.remove('listening');
                    document.getElementById('voiceBtn').innerHTML = '🎤 Ask Me';
                };
            } else {
                updateStatus('Voice input not supported in this browser', '');
                document.getElementById('voiceBtn').style.display = 'none';
            }
        }

        // Toggle voice input - with interruption feature
        function toggleVoiceInput() {
            if (!recognition) return;

            // Interrupt speech if currently speaking
            if (isSpeaking) {
                speechSynthesis.cancel();
                isSpeaking = false;
                updateStatus('Speech interrupted. Ready to listen!', '');
            }

            if (isListening) {
                recognition.stop();
            } else {
                recognition.start();
            }
        }

        // Capture image
        async function captureImage() {
            if (!cameraStarted) {
                updateStatus('Camera not ready yet!', '');
                return;
            }

            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            ctx.drawImage(video, 0, 0);
            
            const dataURL = canvas.toDataURL('image/jpeg', 0.8);
            const base64Data = dataURL.split(',')[1];
            
            updateStatus('Analyzing image...', 'processing');
            
            try {
                const description = await describeImage(base64Data);
                currentImageDescription = description;
                
                updateStatus(`I can see: ${description}`, 'speaking');
                speakText(`I can see: ${description}`);
            } catch (error) {
                console.error('Error describing image:', error);
                const errorMsg = 'Sorry, I had trouble seeing that. Can you try again?';
                updateStatus(`${errorMsg}`, '');
                speakText(errorMsg);
            }
        }

        // Ask question
        async function askQuestion(question) {
            updateStatus('Thinking...', 'processing');

            try {
                const response = await getAIResponse(question);
                updateStatus(`${response}`, 'speaking');
                speakText(response);
            } catch (error) {
                console.error('Error getting AI response:', error);
                const errorMsg = 'Sorry, I had trouble understanding that. Can you try asking again?';
                updateStatus(`${errorMsg}`, '');
                speakText(errorMsg);
            }
        }

        // Describe image using Gemini API
        async function describeImage(base64Image) {
            const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?key=${GEMINI_API_KEY}`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({
                    contents: [{
                        parts: [
                            { text: "Describe this image in a way that's easy for a child to understand. Keep it simple and engaging." },
                            {
                                inline_data: {
                                    mime_type: "image/jpeg",
                                    data: base64Image
                                }
                            }
                        ]
                    }]
                })
            });

            const data = await response.json();
            
            if (data.candidates && data.candidates[0] && data.candidates[0].content) {
                return data.candidates[0].content.parts[0].text;
            } else {
                throw new Error('Failed to get image description');
            }
        }

        // Get AI response using OpenRouter
        async function getAIResponse(question) {
            const messages = [
                {
                    role: "system",
                    content: "You are a friendly AI assistant made for answering children's questions. Keep your responses simple, engaging, and educational. Use minimal emojis and keep responses under 100 words. Be encouraging and positive."
                }
            ];

            if (currentImageDescription) {
                messages.push({
                    role: "system",
                    content: `The child is looking at an image. Here's what I can see in the image: ${currentImageDescription}`
                });
            }

            // Add recent chat history
            chatHistory.slice(-4).forEach(msg => {
                messages.push(msg);
            });

            messages.push({
                role: "user",
                content: question
            });

            const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${OPENROUTER_API_KEY}`,
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({
                    model: "meta-llama/llama-3.3-8b-instruct:free",
                    messages: messages,
                    max_tokens: 150,
                    temperature: 0.7
                })
            });

            const data = await response.json();
            
            if (data.choices && data.choices[0] && data.choices[0].message) {
                const aiResponse = data.choices[0].message.content;
                
                // Update chat history
                chatHistory.push({ role: "user", content: question });
                chatHistory.push({ role: "assistant", content: aiResponse });
                
                // Keep only last 10 messages
                if (chatHistory.length > 10) {
                    chatHistory = chatHistory.slice(-10);
                }
                
                return aiResponse;
            } else {
                throw new Error('Failed to get AI response');
            }
        }

        // Text to speech function with interruption tracking
        function speakText(text) {
            if (!('speechSynthesis' in window)) return;

            // Cancel any ongoing speech
            speechSynthesis.cancel();
            isSpeaking = false;

            // Clean the text - remove more formatting and emojis
            const cleanText = text.replace(/\*\*/g, '').replace(/\*/g, '').replace(/#/g, '').replace(/[🤖🖼️📷🎤🔍💭😕❌🎥🤔]/g, '');

            currentUtterance = new SpeechSynthesisUtterance(cleanText);
            currentUtterance.rate = 0.9;
            currentUtterance.pitch = 1.1;
            currentUtterance.volume = 0.8;

            // Try to use a child-friendly voice
            const voices = speechSynthesis.getVoices();
            const femaleVoice = voices.find(voice => 
                voice.name.includes('Female') || 
                voice.name.includes('Samantha') || 
                voice.name.includes('Karen') ||
                voice.name.includes('Zira')
            );
            
            if (femaleVoice) {
                currentUtterance.voice = femaleVoice;
            }

            currentUtterance.onstart = function() {
                isSpeaking = true;
            };

            currentUtterance.onend = function() {
                isSpeaking = false;
                updateStatus('Ready for your next question! Click "Ask Me" to talk.', '');
            };

            currentUtterance.onerror = function() {
                isSpeaking = false;
            };

            speechSynthesis.speak(currentUtterance);
        }

        // Update status display
        function updateStatus(message, type) {
            const statusDiv = document.getElementById('voiceStatus');
            statusDiv.textContent = message;
            statusDiv.className = `voice-status ${type}`;
        }

        // Load voices when they become available
        speechSynthesis.onvoiceschanged = function() {
            // Voices are now loaded
        };
    </script>
</body>
</html>
